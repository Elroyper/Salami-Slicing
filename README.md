# ğŸ¤– Multi-Model Black-box Jailbreak Framework Suite ğŸ›¡ï¸

> **Security Research Toolbox Built on Salami Slicing Methodology**

## ğŸ“¦ Overview

This repository contains two advanced security research frameworks focused on Large Language Model safety assessment and red-team testing:

- **Salami Attack** ğŸš€ - Innovative **Salami Slicing** progressive attack framework
- **A-Salami Attack** ğŸ”§ - Modern **adaptive multi-turn** attack system

## ğŸ¯ Core Value

- **Progressive Attack Strategy** ğŸ”„: Gradually evolve innocent prompts to potentially harmful outputs
- **Multi-dimensional Evaluation** ğŸ“Š: Combines success rates, score-based, and safety assessments
- **High-performance Processing** âš¡: Parallel testing for large-scale datasets
- **Flexible Model Integration** ğŸ”—: Support for mainstream APIs like OpenAI, Anthropic

## ğŸ”‘ Key Features

- **ğŸ›¡ï¸ Security Integration**: Built-in safety review mechanisms
- **ğŸ“ˆ Diverse Evaluation**: Triple-judge, score-based, and classification testing
- **âš¡ Parallel Acceleration**: Thread pool concurrent processing
- **ğŸ¨ Modular Design**: Flexible extensible architecture
- **ğŸ“‹ Complete Reports**: Automatically generated reproducible JSON results

## ğŸ”¬ Use Cases

- **Academic Security Research** ğŸ“: Model robustness evaluation
- **Enterprise Red-team Testing** ğŸ¢: Security vulnerability discovery
- **Model Safety Certification** âœ…: Pre-deployment security validation
- **Continuous Monitoring** ğŸ“Š: Production environment safety detection

## âš–ï¸ Compliance Statement

**Authorized security testing and research only**. Prohibited for malicious purposes. Users must ensure compliance with relevant API service terms.

---

## ğŸ§­ Quick Start

```bash
cd a_salami/ && python -c "from a_salami import Adaptive_W2SAttack"
cd salami_attack/ && python -c "from salami_attack import W2SAttack"
```

- ğŸ“– [Salami Attack Detailed Documentation](./salami_attack/README.md)
- ğŸ“– [A-Salami Attack Detailed Documentation](./a_salami/README.md)